<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Aula 13 - Metodologia Box-Jenkins (parte 1)</title>
    <meta charset="utf-8" />
    <meta name="author" content="Renato Rodrigues Silva" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Aula 13 - Metodologia Box-Jenkins (parte 1)
## Material fortemente baseado no livro de Morettin e Toloi (2004)
### Renato Rodrigues Silva
### Universidade Federal de Goiás.
### (updated: 2020-08-04)

---

class: middle
##Abordagem de Box e Jenkins (1970).

- Tal metodologia consiste em ajustar modelos auto-regressivos integrados de médias móveis a um conjunto de dados baseado em um ciclo iterativo.

##Resumo:

a.  Uma classe geral de modelos é considerada para a análise (especificação);

b.  Há identificação de um modelo, com base na análise de autocorrelações, autocorrelações parciais e outros critérios;

c. A seguir vem a fase de estimação, na qual os parâmetros do modelo identificado são estimados;

d. Finalmente, há a verificação ou diagnóstico do modelo ajustado, através de uma análise de resíduos, para se saber se este é adequado para os fins em vista (previsão, por exemplo).


- Caso o modelo não seja adequado, o ciclo é repetido, voltando-se à fase de identificação.


---
class: inverse, center, middle
##Função de autocorrelação parcial


---
class: middle
##Função de autocorrelação parcial

- Na aula passada foi visto:

a. Um processo `\(AR(p)\)` tem uma função de autocovariância que decai de acordo com exponenciais e ou senoides amortecidas, infinita em extensão;

b. Um processo `\(MA(q)\)` tem fac finita, no sentido que ela apresenta um corte após o "lag" `\(q\)`;

c. Um processo `\(ARMA(p,q)\)` tem fac infinita em extensão, a qual decai de acordo com exponenciais e ou senoides amortecidas após o "lag" `\(q-p\)`.

- Essas observações serão úteis no procedimento de identificação. Com o intuito de complementar a etapa de identificação, Box, Jenkins e Reinsel (1994) propuseram a utilização da **função de autocorrelação parcial**.


---
class: middle
##Correlação Parcial: Revisão

- Em geral, uma correlação parcial é uma correlação condicional. 

- É a correlação entre duas variáveis sob a suposição de que conhecemos e levamos em conta os valores de algum outro conjunto de variáveis. 

- Por exemplo, considere um contexto de regressão em que `\(y\)` é a variável de resposta e, `\(x_1\)`, `\(x_2\)` e `\(x_3\)` são variáveis preditoras. 

- A correlação parcial entre `\(y\)` e `\(x_3\)` é a correlação entre as variáveis determinadas levando em consideração o quanto `\(y\)` e `\(x_3\)` estão relacionados a `\(x_1\)` e `\(x_2\)` . Para calcular essa correlação obtemos:

a.  O resíduo do modelo de regressão `lm(y ~ x1+ x2)`;

b.  O resíduo do modelo de regressão  `lm(x3 ~ x1+ x2)`;

c. A correlação de Pearson entre esses resíduos.


---
class: middle 

##Obtenção da função de autocorrelação parcial 

A função definida pela seguinte correlação condicional
`\begin{equation}
P_k = \phi_{kk} = Corr(Z_t, Z_{t+k}| Z_{t+1}, \ldots, Z_{t+k-1})
\end{equation}`
é usualmente referida como correlação parcial em análise de séries temporais.

- Vamos denotar por `\(\phi_{kj}\)` o j-ésimo coeficiente de um modelo `\(AR(k)\)`, de tal modo que `\(\phi_{kk}\)` seja o último coeficiente. Sabemos que

`$$\rho_j = \phi_{k1} \rho_{j-1} + \rho_{k2} \rho_{j-2} + \ldots + \phi_{kk} \rho_{j-k}, \phantom{111} j = 1, \ldots, k,$$`

a partir das quais obtemos as equações de Yule- Walker 


`\begin{align}
\rho_1 =&amp; \phi_{k1} \rho_0 + \phi_{k2} \rho_1 + \ldots + \phi_{kk} \rho_{k-1} \\
\rho_2 =&amp; \phi_{k1} \rho_1 + \phi_{k2} \rho_0 + \ldots + \phi_{kk} \rho_{k-2} \\
\vdots \\
\rho_k =&amp; \phi_{k1} \rho_{k-1} + \phi_{k2} \rho_{k-2} + \ldots + \phi_{kk} \rho_{0}
\end{align}`


---
##Solução Geral da Equação de Yule-Walker 

Para `\(k=1\)` temos `\(\rho_1 = \phi_{11} \rho_0\)`, logo `\(\phi_{11} = \rho_1.\)` Para `\(k=2\)`, temos:

`\begin{align}
\rho_1 =&amp; \phi_{k1} 1 + \phi_{k2} \rho_{1} \\
\rho_2 =&amp; \phi_{k1} \rho_1 + \phi_{k2} 1 
\end{align}`
- Observe que `\(\rho_0 = 1\)` e `\(\rho_{-j} = \rho_{j}.\)` Logo, 

`\begin{eqnarray}
\phi_{22} = \frac{
\left|
\begin{array}{cc}
1       &amp;  \rho_1 \\
\rho_1  &amp;  \rho_2 
\end{array} \right|}
{
\left|
\begin{array}{cc}
1       &amp;  \rho_1 \\
\rho_1  &amp;  1 
\end{array} \right|
} = \frac{\rho_2-\rho_1^2}{1-\rho_1^2}.
\end{eqnarray}`

Assim, em geral, temos:

`$$\phi_{kk} = \frac{|\mathbf{P}^{*}_k|}{|\mathbf{P}_k|},$$`
em que `\(|\mathbf{P}_k|\)` é a matriz de autocorrelações  e `\(|\mathbf{P}^{*}_k|\)` é a matriz de autocorrelações com 
a última coluna substituídas pelo vetor de autocorrelações.

---
##Solução Geral da Equação de Yule-Walker 

- Será necessário estimar a facp de um processo AR, MA ou ARMA.

- Uma maneira consiste em estimar, sucessivamente, modelos auto-regressivos de ordens `\(p = 1, 2, 3, \ldots\)`, por mínimos quadrados e tomar as estimativas do último coeficiente de cada ordem.

- Outra maneira consiste em substituir nas equações de Yule=Walker as fac `\(\rho_j\)` por suas estimativas

`$$\rho_j = \hat{\phi}_{k1} r_{j-1} + \ldots + \hat{\phi}_{kk} r_{j-k}, \phantom{111} j = 1, \ldots, k,$$`
e resolver estas equações para `\(k = 1, 2, \ldots\)`

- Pode-se demonstrar que `\(\phi_{kk}\)` é igual à correlação parcial entre as variáveis `\(Z_t\)` e `\(Z_{t-k}\)` ajustadas às variáveis intermediárias `\(Z_{t-1}, \ldots, Z_{t-k+1}\)`.

- Ou seja, `\(\phi_{kk}\)` mede a correlação remanescente entre `\(Z_t\)` e `\(Z_{t-k}\)` depois de eliminada a influência de `\(Z_{t-1}, \ldots, Z_{t-k+1}.\)`

---
##Estimativa Função de Autocorrelação

- Lembremos que a fac `\(\rho_j\)` é estimada por

`$$r_j = \frac{c_j}{c_0}, \phantom{11} j = 0,1, \ldots, N-1.$$`
em que `\(c_j\)` é a estimativa da facv `\(\gamma_j,\)`

`$$c_j = \frac{1}{N}\sum_{t=1}^{N-j} \left[(Z_t - \bar{Z})(Z_{t+j} - \bar{Z}) \right], \phantom{111} j = 0, 1, \ldots, N - 1.$$`
sendo `\(\bar{Z} = \frac{1}{N}\sum_{i=1}^N Z_t\)` a média amostral. Lembremos que `\(r_j = r_{-j}.\)`

- A variância de `\(r_j\)`, para um processo estacionário normal, é dada por:

`$$Var(r_j) \approx \frac{1}{N} \sum_{\nu = -\infty}^{\infty}[\rho_{\nu} +
\rho_{\nu+j}\rho_{\nu-j} - 4\rho_{j}\rho_{\nu-j} +  2\rho_{j}^2\rho_{j}^2],$$`

- Para um processo em que as autocorrelações são nulas para `\(\nu &gt; q\)`, tem-se:

`$$Var(r_j) \approx \frac{1}{N}\left[1 + 2\sum_{\nu=1}^q \rho_{\nu}^2 \right] \Rightarrow \hat{\sigma}^2 \approx \frac{1}{N}\left[1 + 2\sum_{\nu=1}^q r_{\nu}^2 \right], \phantom{11} j &gt; q.$$` 


---
##Intervalo de confiança aproximado para as autocorrelações

- Para `\(N\)` suficientemente grande e sob a hipótese que `\(\rho_j = 0,\)` para `\(j &gt; q,\)` a distribuição de `\(r_j\)` é aproximadamente normal, com média igual a zero e variância dada por `\(Var(r_j) \approx \frac{1}{N}\left[1 + 2\sum_{\nu=1}^q \rho_{\nu}^2 \right].\)`

- O intervalo é dado por

`$$r_j \pm t_{\gamma} \hat{\sigma}(r_j).$$`
em que `\(t_{\gamma}\)` é o valor da estatística `\(t\)` de Student com `\(N - 1\)` graus de liberdade.


---
class: inverse, center, middle
##Procedimento de identificação


---
class: middle
##Procedimento de identificação

- O objetivo da identificação é determinar os valores `\(p\)`, `\(d\)` e `\(q\)` do modelo `\(ARIMA(p,d,q)\)`.

- O procedimento de identificação consiste de três partes:

a.  Verficar se existe necessidade de uma transformação na série original, com o objetivo de estabilizar sua variância.

b. Tomar diferenças da série tantas vezes quantas necessárias para se obter uma série estacionária, de modo que o processo `\(\Delta^d Z_t\)` seja reduzido a um `\(ARMA(p.q).\)`

c.  Identificar o processo `\(ARMA(p,q)\)` resultante, através da análise das autocorrelações e autocorrelações parciais estimadas, cujos os comportamentos devem imitar os comportamentos das respectivas quantidades teóricas.





---
class: middle
###Comportamento das fac e facp de um processo ARIMA(p,d,q)


| `\((1,d,0)\)`                 |  `\((0,d,1)\)`             |
| --------------------------| -----------------------|
| `\(\rho_{k}\)` decai exponencialmente      | somente `\(\rho_1 \neq 0\)`|    
| somente `\(\phi_{11} \neq 0\)`| decaimento exponencial dominante |
| `\((2,d,0)\)`                 |  `\((0,d,2)\)`             |
| `\(\rho_{k}\)` mistura de exponenciais e senoides amortecidas  | somente `\(\rho_1 \neq 0\)` e `\(\rho_1 \neq 0\)`|    
| somente `\(\phi_{11} \neq 0\)` e `\(\phi_{22} \neq 0\)`| dominanda por mistura de exponenciais ou senoides amortecidas|


---
class: middle
###Comportamento das fac e facp de um processo ARIMA(p,d,q)

| `\((1,d,1)\)`                 
| -------------------------------------------------|
| `\(\rho_{k}\)` decai exponencialmente após lag 1 
| `\(\phi_{11}\)` é dominada por decaimento exponencial após lag 1|

#####Observação Importante !!!

- Dada a forma complicada da fac e facp de um modelo ARMA, estas funções não são muito úteis para identificar tais modelos.

- O que se recomenda, neste caso, é ajustar alguns modelos de baixa ordem, por exemplo, (1,1), (1,2), (2,1) e utilizar critérios que permitam escolher o modelo mais adequado.


---
class: middle
###Comentários úteis sobre identificação de modelos McLeod (1983)

- O maior problema neste estágio do procedimento é evitar um excesso de diferenças.

- Um número excessivo de diferenças resulta em um valor negativo da autocorrelação de ordem 1 da série diferençada, neste caso `\(\rho_1 = -0.5.\)`

- Quando a série é corretamente diferençada, a variância da série transformada diminui, por outro lado, excesso de diferenças aumentará essa variância.


---
class: inverse, center, middle
##Formas alternativas de identificação


---
class: middle
###Critério de Informação de Akaike (1974)

- Akaike (1974) sugere escolher o modelo cujas ordens `\(k\)` e `\(l\)` minimizam o critério

`$$AIC(k,l) = \ln{\hat{\sigma}^2_{k,l}} + \frac{2(k+l)}{N},$$`
pois os valores de `\(k\)` e `\(l\)` que minimizam esta última expressão são os mesmos que minimizam.


###Critério de Informação Bayesiano (1978)

- Schwarz (1978) sugerem minimizar o critério de informação Bayesiano (1978), que no caso de um modelo ARMA é dado por:

`$$BIC(k,l) = \ln{\hat{\sigma}^2_{k,l}} + (k+l)\frac{\ln N}{N}.$$`
em que `\(\hat{\sigma}^2_{k,l}\)` é a estimativa de máxima verossimilhança da variância residual do modelo ARMA(k,l).


---
class: inverse, center, middle
##Transformações e Teste e Raízes Unitárias

---
##Teste de Raíz Unitárias baseando-se em um Modelo AR(1)


- Por questões didáticas, vamos assumir `\(\mu = 0\)` e ausência de tendência determinística.

- Sendo assim, considere o seguinte modelo:

`$$Z_t = \phi Z_{t-1} + a_t.$$`

- Observe que se `\(\phi=1\)`, temos um passeio aleatório, ou seja, uma série não estacionária. Por outro lado,  se `\(\phi &lt; 1,\)` temos uma série estacionária. O estimador de mínimos quadrados de `\(\phi\)` é dado por:

`$$\hat{\phi} = \frac{\sum_{t=1}^N Z_{t-1}Z_t}{\sum_{t=1}^N Z_{t-1}^2}.$$`

- No entanto, por detalhes técnicos que eu não vou mostrar aqui, não é possível obter a distribuição de `\(\hat{\phi}\)` quando a série é não estacionária. A distribuição t somente é válida para `\(\phi &lt; 1\)`.


---
##Teste de Raíz Unitárias baseando-se em um Modelo AR(1)

- Para resolver esse problema, procede-se da seguinte maneira.

`\begin{align}
Z_t  =&amp; \phi Z_{t-1} + a_t \\
Z_t - Z_{t-1} =&amp; \phi Z_{t-1} - Z_{t-1} + a_t \\
\Delta Z_t =&amp; (\phi - 1)  Z_{t-1}+ a_t \\
\Delta Z_t =&amp; \gamma Z_{t-1} + a_t.
\end{align}`

- Nesse caso, a hipótese nula fica: `\(H_0: \gamma =0\)` (série não estacionária) e `\(H_0: \gamma &lt; 0\)` (série estacionária). 

- Ainda, com essa reparametrização é possível obter a distribuição assintótica da estatística do teste. 

- Esse teste é chamado **Teste de Dickey-Fuller**.


---
class: middle
##Teste de Dickey-Fuller 

- Agora vamos considerar que o modelo possua uma constante "drift" e uma tendência determinística.

O teste de Dickey-Fuller verifica se `\(\gamma = 0\)` no seguinte modelo

`$$\Delta Z_t = \alpha + \beta t + \gamma Z_{t-1} + \epsilon_t,$$`

- Nesse caso, a hipótese nula é a mesma, ou seja, que a série seja não estacionária. Entretanto, agora a hipótese alternativa pode ser que a série seja estacionária ou não estacionária determinística.








---
class: middle
##Teste de Dickey-Fuller Aumentado

- O teste de Dickey-Fuller Aumentado permite incluir termos de processos autoregressivos de ordens maiores. Contudo, ainda testa-se se `\(\gamma = 0.\)`

`$$\Delta Z_t = \alpha + \beta t + \gamma Z_{t-1} + \delta_1 \Delta Z_{t-1} + \delta_2 \Delta Z_{t-2} + \ldots,$$`
- **Importante!!!**: As hipóteses nula para ambos testes é que os dados não são estacionários. 

####Material Extra

- Nesse livro [aqui](https://nwfsc-timeseries.github.io/atsa-labs/sec-boxjenkins-aug-dickey-fuller.html) podem ser encontrados algumas explicações sobre o assunto.

- O portal [action](http://www.portalaction.com.br/series-temporais/141-teste-de-dickey-fuller-aumentado) também têm informações a respeito do tema.

- Além disso, vale ressaltar que existem outros testes de raízes unitárias tais como:
Teste de Phillips - Perron e KPSS.

---
class: middle
##Transformações

-  Há basicamente, duas razões para se transformar os dados originais: estabilizar a variância e/ou tornar o efeito sazonal aditivo.

- Se os dados mostram variação que aumentam ou decresece com o nível da série, então uma transformação pode ser útil.

- Uma outra razão para efetuar transformações é obter uma distribuição para os dados mais simétrica e próxima da normal.


###Algumas altervativas de transformações

- Transformações logaritmicas

- Transformações Box-Cox

- Maiores detalhes podem ser vistos [aqui](https://otexts.com/fpp2/transformations.html)


---
class: middle, center, inverse
##Exemplo prático no R

---

####Carregando as bibliotecas


```r
library(tidyverse)
library(httr)
library(xlsx)
library(ggfortify)
```

####Lendo os dados


```r
url1 = 'https://www.ime.usp.br/~pam/ICV.xls'
a = GET(url1, write_disk(tf &lt;- tempfile(fileext = ".xls")))
dat =  as_tibble(read.xlsx(tf, sheetIndex = 1))
ts(dat$ICV) %&gt;% autoplot()
```


####Plotando a série


```r
 ts(dat$ICV) %&gt;% autoplot()
```


---

####Plotando a série

![](Aula_13_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

- Os modelos ARIMA são capazes de descrever séries estacionárias e não estacionárias, mas que não apresentem comportamento explosivo.



---
####Plotando a série usando a transformação logarítmica


```r
 ts(log(dat$ICV)) %&gt;% autoplot()
```


####Plotando a série usando a transformação logarítmica com uma diferença


```r
 ts(diff(log(dat$ICV))) %&gt;% autoplot()
```

####Plotando a série usando a transformação logarítmica com duas diferenças


```r
 ts(diff(log(dat$ICV), differences=2)) %&gt;% autoplot()
```


---
####Plotando a série usando a transformação logarítmica

![](Aula_13_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;


---
####Plotando a série usando a transformação logarítmica com uma diferença

![](Aula_13_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;


---
####Plotando a série usando a transformação logarítmica com duas diferenças

![](Aula_13_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---
####Teste de Duckey Fuller Aumentado apenas com transformação


```r
tseries::adf.test(ts(log(dat$ICV)),k=0)
```


####Teste de Duckey Fuller Aumentado com transformação e 1 diferença


```r
tseries::adf.test(diff(ts(log(dat$ICV)),k=0)
```

####Teste de Duckey Fuller Aumentado com transformação e 2 diferenças


```r
tseries::adf.test(diff(ts(log(dat$ICV)), differences=2),k=0)
```

---
####Teste de Duckey Fuller Aumentado apenas com transformação


```
## 
## 	Augmented Dickey-Fuller Test
## 
## data:  ts(log(dat$ICV))
## Dickey-Fuller = 0.53272, Lag order = 0, p-value = 0.99
## alternative hypothesis: stationary
```


####Teste de Duckey Fuller Aumentado com transformação e 1 diferença


```
## 
## 	Augmented Dickey-Fuller Test
## 
## data:  diff(ts(log(dat$ICV)))
## Dickey-Fuller = -7.8138, Lag order = 0, p-value = 0.01
## alternative hypothesis: stationary
```


####Teste de Duckey Fuller Aumentado com transformação e 2 diferenças

```
## 
## 	Augmented Dickey-Fuller Test
## 
## data:  diff(ts(log(dat$ICV)), differences = 2)
## Dickey-Fuller = -14.348, Lag order = 0, p-value = 0.01
## alternative hypothesis: stationary
```


---
class: middle

####Função de Autocorrelação


```r
acf(diff(ts(log(dat$ICV)), differences=1))
```

####Função de Autocorrelação Parcial


```r
pacf(diff(ts(log(dat$ICV)), differences=1))
```


---
####Função de Autocorrelação

![](Aula_13_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;


---
####Função de Autocorrelação Parcial

![](Aula_13_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;



---
class: middle

####Função de Autocorrelação


```r
acf(diff(ts(log(dat$ICV)), differences=2))
```

####Função de Autocorrelação Parcial


```r
pacf(diff(ts(log(dat$ICV)), differences=2))
```

---
class: middle

####Função de Autocorrelação

![](Aula_13_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;

---

####Função de Autocorrelação Parcial

![](Aula_13_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;

---
class: middle
##Modelo Escolhido pela metodologia Box e Jenkins

- Observando os resultados dos testes de raízes unitárias tanto `\(d=1\)` como `\(d=2\)` proporciona séries estacionárias

- Seguindo as recomendações feitas por McLeod (1983), observa-se que para `\(d=2\)` (duas diferenças),  a estimativa de `\(\rho_1\)` é próximo de `\(-0.5\)` (-0.31), o que indica um excesso de diferença.

- Portanto,  olhando as estimativas de autocorrelações e autocorrelações parciais com `\((d=1)\)`, tem-se que o modelo escolhido é `\(ARIMA(1,1,0).\)`



---
##Usando o critério AIC


```r
auto.arima(ts(dat$ICV), lambda="auto", allowdrift = TRUE)
```


```r
auto.arima(ts(log(dat$ICV)), lambda=NULL, allowdrift = TRUE)
```


---
##Usando o critério AIC


```
## Series: ts(dat$ICV) 
## ARIMA(0,1,1) with drift 
## Box Cox transformation: lambda= -0.4217412 
## 
## Coefficients:
##          ma1   drift
##       0.3539  0.0022
## s.e.  0.0845  0.0001
## 
## sigma^2 estimated as 8.575e-07:  log likelihood=632.23
## AIC=-1258.46   AICc=-1258.24   BIC=-1250.28
```


###Interessante discussão na web

- Esse post escrito na rede social linkdln discute um pouco sobre escolha automática de [modelos](https://www.linkedin.com/pulse/note-autoarima-boxcox-transform-al-yazdani/)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
