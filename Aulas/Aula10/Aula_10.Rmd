---
title: "Aula 10 - Modelos de Suavização Exponencial"
subtitle: 
author: "Renato Rodrigues Silva"
institute: "Universidade Federal de Goiás."
date: "(updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false


---
class: middle, inverse, center
#Métodos de suavização


---
class: middle, 

##Revisão - Aulas passadas

```{r, echo = FALSE, warning=FALSE, message=FALSE}

library(tidyverse)
library(ggpmisc)
library(knitr)
library(kableExtra)
library(lubridate)
library(httr)
library(xlsx)
library(fpp2)
library(forecast)
library(tsibble)
library(TTR)
library(forecast)
```

####Tendência: (Rob Hyndman)

-  Uma mudança a longo prazo no nível da série. Crescimento ou descrescimento [curso](https://github.com/robjhyndman/ETC3550Slides/raw/fable/2-tsgraphics.pdf). 


Modelo de decomposição de séries temporal sem levar em consideração o componente sazonal.

$$Z_t = T_t + a_t.$$

####Métodos para Estimar Tendência: (Morretin & Toloi 2004)

- Ajuste de uma função no tempo (polinômios, exponenciais e etc);

- Filtrar os valores da série ao redor de um ponto (médias móveis centradas);

- Suavisar os valores da série através de um ajuste de regressão loess.

---
class: middle, 
##Métodos de Suavização - Introdução (Morettin & Toloi 2004)

- A maioria dos métodos de previsão baseia-se na ideia de que observações passadas contêm informações sobre o padrão de comportamento da série temporal.

- O propósito dos métodos é distinguir o padrão de qualquer ruído que possa estar contido nas observações e então usar esse padrão para prever valores futuros da série.

- Uma grande classe de métodos de previsão, que tenta tratar ambas as causas de flutuações em séries de tempo, é das suavizações.

- Técnicas específicas desse tipo assumem que os valores de extremos da série representam a aleatoriedade e, assim, por meio da suavização desses extremos, pode-se identificar o padrão básico. 


---
class: middle

##Modelos para séries localmente constantes 

- Vamos considerar, nesta seção, o caso de uma série temporal $Z_1, \ldots, Z_N,$ localmente composta de seu nível mais um ruído aleatório, isto é,

$$Z_t = \mu_t + a_t, \phantom{11} t = 1, \ldots, N,$$
em que $E[a_t] = 0$, $Var[a_t] = \sigma^2_a$ e $\mu_t$ é um parâmetro desconhecido, que pode variar lentamente com o tempo.

- [Outras explicações](http://www.math.hkbu.edu.hk/~hpeng/Math4826/Chapter3.pdf)

- [Outras explicações](http://www.imm.dtu.dk/~hmad/time.series.analysis/slides/lect03.pdf)

---
class: middle

###Média móveis simples - Forma recursiva

$$M_t = \frac{Z_t + Z_{t-1} + \ldots + Z_{t-r+1}}{r} = \frac{1}{r}\sum_{k=0}^{r-1} Z_{t-k},$$

Usando a expressão anterior temos

$$M_{t-1} = \frac{Z_{t-1} + Z_{t-2} + \ldots + Z_{t-r}}{r}$$
Logo,

--
$$M_t = \frac{Z_t + Z_{t-1} + \ldots + Z_{t-r+1}}{r}$$
--
$$= \frac{Z_t}{r} + \frac{Z_{t-1} + Z_{t-2} + \ldots + Z_{t-r+1}}{r} +\frac{Z_{t-r}}{r} -  \frac{Z_{t-r}}{r}$$

--
$$=\frac{Z_t- Z_{t-r}}{r} + \frac{Z_{t-1} + Z_{t-2} + \ldots + Z_{t-r}}{r}$$

--
$$=\frac{Z_t - Z_{t-r}}{r} + M_{t-1}$$


---
class: middle
##Previsão

- A previsão de todos os valores futuros é dada pela última média móvel calculada, isto é, 

$$\hat{Z}_{t+h} =  M_t = \frac{1}{r}\sum_{k=0}^{r-1}\mu_{t-k}, \phantom{111} \forall \phantom{|} h > 0.$$

ou

$$\hat{Z}_{t+h}  = \hat{Z}_{t+h-1}  + \frac{Z_t - Z_{t-r}}{r}, \phantom{11} h > 0.$$ 

- Essa equação pode ser interpretada como um mecanismo de atualização de previsão, pois a cada instante corrige a estimativa prévia de $\hat{Z}_{t+h}.$

####Média de Previsão 

$$E[\hat{Z}_{t+h} ] = E\left(\frac{1}{r}\sum_{k=0}^{r-1} Z_{t-k}\right) = \frac{1}{r}\sum_{k=0}^{r-1} \mu_{t-k}.$$



---
class: middle
##Erro quadrático médio de previsão

--
$$\mbox{EQM}[\hat{Z}_{t+h} ] = E\left[Z_{t+h} - \hat{Z}_{t+h}\right]^2$$

--
$$E\left[ Z_{t+h} - \sum_{k=0}^{r-1} \frac{Z_{t-k}}{r}\right]^2$$

--
$$E\left[ Z_{t} - \sum_{k=0}^{r-h-1} \frac{Z_{t-h-k}}{r}\right]^2$$
--
$$E[Z_t^2] - \frac{2}{r} \sum_{k=0}^{r-h-1} E[Z_t Z_{t-h-k}] +\frac{1}{r^2}\sum_{k=0}^{r-h-1}\sum_{j=0}^{r-h-1}E[Z_{t-h-k} Z_{t-h-j}]$$

--
$$=\gamma_t(0) - \frac{2}{r}\sum_{k=0}^{r-h-1} \gamma_t(h + k) +
\frac{1}{r^2} \sum_{k=0}^{r-h-1} \sum_{j=0}^{r-h-1}  \gamma_{t-h-k}(j - k)$$

em que $\gamma_t(h) = E[Z_t Z_{t-h}] = Cov(Z_t,Z_{t-h-k}) + \mu_t\mu_{t-h-k}, \phantom{111} \forall \phantom{|} h > 0.$

---
class: middle

###Caso particular:  Modelo com média globalmente constante

$$Z_t = \mu + a_t,$$

- Nesse caso, temos:

$$E[\hat{Z}_{t+h}] = \frac{1}{r}\sum_{k=0}^{r-1}\mu = \mu$$
e  variância é dada por:

$$Var[\hat{Z}_{t+h}] = Var\left(\sum_{k=0}^{r-1} \frac{Z_{t-k}}{r}\right) = \frac{\sigma_a^2}{r}.$$

##Intervalo de Confiança

- Assumindo $a_t \sim N(0, \sigma^2_{a})$, pode-se afirmar que $\hat{Z}_{t+h} \sim N(\mu, \frac{\sigma^2_{a}}{r})$, podemos construir um intervalo de confiança dado por:

$$\left(\hat{Z}_{t+h} - z_{tab} \frac{\sigma_{a}}{\sqrt{r}}; \hat{Z}_{t+h}  + z_{tab} \frac{\sigma_{a}}{\sqrt{r}}\right).$$

---
class: middle
##Determinação de $r$

- As propriedades do método dependem do número de observações utilizadas na média (valor de $r$).

- Um valor grande de $r$ faz com que a previsão acompanhe lentamente as mudanças do parâmetro $\mu_t$.

- Um valor pequeno implica numa reação mais rápida.

####Casos extremos:

- $r=1$, então o valor mais recente da série é utilizado como previsão de todos os valores futuros ("método ingênuo");

- $r=N$, então a previsão será igual a média aritmética de todos os dados observados. Este caso só é indicado quando a série é altamente aleatória.


---
class: middle
##Procedimento objetivo

- Um procedimento objetivo é selecionar o valor de $r$ que fornece a "melhor previsão" a um passo das observações já obtidas ("backforecasting"), ou seja, 

- Encontrar o valor de $r$ que minimize 

$$S = \sum_{t=l+1}^N(Z_t - \hat{Z}_{t-1}(1))^2,$$
em que $l$ é escolhido de tal modo que o valor inicial utilizado em $M_t = \frac{Z_t - Z_{t-r}}{r} + M_{t-1}$ não influencie a previsão.

---
class: middle
##Vantagens e desvantagens do método (Morettin)

###Vantagens

- simples aplicação;

- é aplicável quando se tem um número pequeno de observações;

- permite uma flexibilidade grande devido à variação de $r$ de acordo com o padrão da série.

###Desvantagens

- necessidade de armazenar pelo menos $(r-1)$ observações;

- dificuldade em determinar o valor de $r$.

###Obs:

- Na prática, o método de móveis não é utilizado frequentemente.

---
class: middle
##Métodos de médias móveis - Aplicação

- Vamos aplicar o método de médias móveis à série $A_6$ CO, no período de primeiro de janeiro a 30 de abril de 1997.

- Vamos ajustar esse modelo utilizando $r=7, r=14$ e $r=21.$

- Para cada ajuste vamos calcular o erro quadrático médio.

---
class: middle
##Métodos de médias móveis - Aplicação



```{r, echo = FALSE, warning=FALSE, message=FALSE}

url1 = 'https://www.ime.usp.br/~pam/poluicao.xls'
a = GET(url1, write_disk(tf <- tempfile(fileext = ".xls")))
dat =  as_tibble(read.xlsx(tf, sheetIndex = 1))
datCO = ts(dat$co[1:120], c(1997,1),c(1997,120), frequency=365)


plot.ts(datCO)
```

---
class: middle
##Métodos de médias móveis - Aplicação


```{r, echo = FALSE, warning=FALSE, message=FALSE}

n = 120

dat2 = tibble(data = rep(1:120,4),
             co = c(datCO,
                         SMA(datCO, 7),
                         SMA(datCO, 14),
                         SMA(datCO, 21)
                         ),
              obs_estimadores = c(rep("CO",n),
                        rep("mm7",n),
                        rep("mm14",n),
                        rep("mm21",n)
                        )
)
ggplot(dat2, aes(data, co)) + 
  #geom_point(position=position_jitter(1,3), pch=21, fill="#FF0000AA") +
  geom_line(aes(y=co,col= obs_estimadores )) +  theme_bw() + xlab('Data (Diaria)') + 
  ylab('CO')
  

```


---
class: middle
####Métodos de médias móveis - Aplicação


```{r, echo = FALSE, warning=FALSE, message=FALSE}


data.frame(dados = datCO,
           mm7 = SMA(datCO, 7),
           mm14 = SMA(datCO, 14),
           mm21 = SMA(datCO, 21))[106:120,]

```                       
                         
####Valores de EQM 

- $r=7$, (`r  mean(c(datCO-SMA(datCO, 7))^2,na.rm=T)`);

- $r=14$, (`r  mean(c(datCO-SMA(datCO, 14))^2,na.rm=T)`);

- $r=21$, (`r  mean(c(datCO-SMA(datCO, 21))^2,na.rm=T)`);



---
class: middle
##Métodos de suavização exponencial simples (SES)

###Motivação 

- O método de médias móveis considera todas as observações (recentes e mais remotas) com o mesmo peso. 

###Definição do método

####Suavizador Ponderado exponencialmente

$$\sum_{k=0}^{N-1} \theta^k Z_{N-k} = Z_N+ \theta Z_{N-1} + \theta^2 Z_{N-2} + \ldots +
\theta^{N-1} Z_1.$$
em que $-1 < \theta < 1$ [progressão geométrica](https://www.mathsisfun.com/algebra/sequences-sums-geometric.html).

- Perceba que nesse suavizador, observações recentes tem um peso maior que observações passadas.

- Perceba também que a soma dos pesos é uma soma de progressão geométrica
$\sum_{k=0}^{N-1} \theta^k = \frac{1 - \theta^N}{1 - \theta}$ que não necessariamente soma 1.


---
class: middle
##Métodos de suavização exponencial simples (SES)

- Para resolver esse problema, multiplicamos $\sum_{k=0}^{N-1} \theta^k$ por $\frac{1 - \theta}{1 - \theta^N}$. No entanto, para valores de $N$ suficientemente grandes, $\theta^N \rightarrow 0$, logo $\frac{1 - \theta}{1 - \theta^N} \rightarrow (1 - \theta).$

- Assim temos

--
$$\bar{Z}_N = (1 - \theta) \sum_{t=0}^{N-1} \theta^t Z_{N-t}$$ 

--
$$= (1 - \theta)(Z_N + \theta Z_{N-1} + \theta^2 Z_{N-2} + \ldots + \theta ^{N-1}Z_1)$$
--
$$= (1 - \theta)Z_N + \theta (1 - \theta)(Z_{N-1} + \theta Z_{N-2} + \ldots + \theta ^{N-2}Z_1)$$

--
$$= (1 - \theta)Z_N +  \theta \bar{Z}_{N-1}.$$

Fazendo $\alpha = (1 - \theta)$ e generalizando para um $t=1,\ldots, N$, temos $\bar{Z}_t = \alpha Z_t +  (1 - \alpha) \bar{Z}_{t-1},$ em que $\bar{Z}_0 = Z_1.$

---
class: middle
##Métodos de suavização exponencial simples (SES)

###Procedimento

$$\bar{Z}_t = \alpha Z_t + (1 - \alpha) \bar{Z}_{t-1}, \phantom{111} \bar{Z_0} = Z_1, \phantom{111} t = 1, \ldots, N.$$
ou

$$\bar{Z}_t = \alpha \sum_{k=0}^{t-1} (1 - \alpha)^k  Z_{t-k} + (1-\alpha)^t\bar{Z}_0,  \phantom{111} t = 1, \ldots, N.$$

- Observe que  $\bar{Z}_1 = \alpha Z_1 + (1 - \alpha) \bar{Z}_{0} \Rightarrow  \alpha Z_1 + (1 - \alpha) Z_1 = Z_1$,  portanto, $\bar{Z_0} = \bar{Z_1} = Z_1.$ [somatório](https://math.stackexchange.com/questions/35080/upper-limit-of-summation-index-lower-than-lower-limit), [somatório2](https://pt.wikipedia.org/wiki/Somat%C3%B3rio).



###Efetuando a expressão anterior temos

$$\bar{Z}_t = \alpha Z_t + \alpha(1 - \alpha) Z_{t-1} + \alpha (1  - \alpha)^2 Z_{t - 2} + \ldots + \alpha(1 - \alpha)^{t-1} Z_{1} + (1 - \alpha)^{t}\bar{Z}_0,$$
o que significa que a SES é uma média ponderada que dá pesos maiores às observações mais recentes, o que é uma vantagem ao método de médias móveis.


---
class: middle
###Previsão

$$\hat{Z}_{t+h}  = \bar{Z}_t, \phantom{111} \forall h > 0,$$

$$\hat{Z}_{t+h} =  \alpha Z_t + (1 - \alpha) \hat{Z}_{t+h-1},$$

Pode-se provar que para $h=1$, tem-se

$$\hat{Z}_{t+1} = \alpha e_t + \hat{Z}_t,$$
em que $e_t = Z_t - \hat{Z}_{t}$.


---
class: middle
###Demonstração:

--
$$\hat{Z}_{t+1} = \alpha Z_t + (1 - \alpha) \hat{Z}_{t}$$
--
$$= \alpha Z_t - \alpha \hat{Z}_{t} + \hat{Z}_{t}$$
--
$$= \alpha (Z_t - \hat{Z}_{t}) + \hat{Z}_{t}$$

--
$$= \alpha e_t + \hat{Z}_{t}$$


- Assim, a nova previsão pode ser obtida da anterior, adicionando-se um múltiplo do erro de previsão, indicando que a previsão está sempre alerta a mudanças no nível de série, revelada pelo erro de previsão.

---
class: middle
##Previsão - Propriedades

###Valor Esperado

--
$$E[\hat{Z}_{t+h}] = E[\alpha \sum_{k=0}^{t-1} (1 - \alpha)^k  Z_{t-k} + (1-\alpha)^t\bar{Z}_0]$$
--
$$=\alpha \sum_{k=0}^{t-1} (1 - \alpha)^k E[Z_{t-k}] + (1-\alpha)^t E[\bar{Z}_0]$$

--
$$\approx  \alpha \sum_{k=0}^{t-1} (1 - \alpha)^k \mu_{t-k}$$

---
class: middle
###Erro Quadrático Médio da Previsão

--
$$\mbox{EQM}[\hat{Z}_{t+h} ] = E\left[Z_{t+h} - \hat{Z}_{t+h}\right]^2 = E\left[ Z_{t+h} -  \alpha\sum_{k=0}^{t-1} (1 - \alpha)^k Z_{t-k} \right]^2$$


--
$$= E\left[ Z_{t} - \alpha\sum_{k=0}^{t-h-1} (1 - \alpha)^k Z_{t-h-k}\right]^2$$
--
$$= E[Z_t^2] - 2\alpha \sum_{k=0}^{t-h-1}(1-\alpha)^k E[Z_t Z_{t-h-k}] +\alpha^2\sum_{k=0}^{t-h-1}\sum_{j=0}^{t-h-1}(1 - \alpha)^{k+j} E[Z_{t-h-j} Z_{t-h-k}]$$

--
$$=\gamma_t(0) - 2\alpha\sum_{k=0}^{t-h-1}(1-\alpha)^k \gamma_t(h + k) +
\alpha^2\sum_{k=0}^{t-h-1}\sum_{j=0}^{t-h-1}(1 - \alpha)^{k+j}  \gamma_{t-h-k}(j - k)$$



---
class: middle
###Determinação da constante $\alpha$ (Morettin)

- Quanto menor for o valor de $\alpha$ mais estáveis serão as previsões finais, uma vez que a utilização de baixo valor de $\alpha$ implica que pesos maiores serão dados as observações.

- Consequentemente, qualquer flutuação aleatória, no presente, exercerá um peso menor no cálculo da previsão.

- Em geral, quanto mais aleatória for a série  estudada, menores serão os valores da constante de suavização.

- O efeito de $\alpha$ grande ou pequeno é completamente análogo (em direção oposta) ao efeito do parâmetro $r$ no método de MMS.

- Um procedimento mais objetivo é selecionar o valor que fornece a "melhor previsão" das observações já obtidas.

---
class: middle

###Vantagens da SES

- fácil de entendimento;

- grande flexibildiade permitida pela variação da constante de suavização 
- necessidade de armazenar somente $Z_t$, $\bar{Z}_t$ e $\alpha$

###Desvantagens da SES

- A principal desvantagem é a dificuldade em determinar o valor mais apropriado da constante de suavização.


---
class: middle
##Métodos suavização exponencial simples - Aplicação

- Vamos aplicar o método de médias móveis à série $A_6$ $NO_2$, no período de primeiro de janeiro a 30 de abril de 1997.

- Vamos ajustar esse modelo utilizando $\alpha = 0.5502$. 

---
class: middle
##Métodos suavização exponencial simples - Aplicação


```{r, echo = FALSE, warning=FALSE, message=FALSE}

datNO2 = ts(dat$no2[1:120], c(1997,1),c(1997,120), frequency=365)


plot.ts(datNO2)
```

---
class: middle
##Métodos suavização exponencial simples - Aplicação


```{r, echo = FALSE, warning=FALSE, message=FALSE}

alpha  = 0.5502

SES = HoltWinters(datNO2, beta=FALSE, gamma=FALSE, alpha=0.5502)

dat2 = tibble(data = rep(1:120,2),
             no2 = c(datNO2,
                     c(NA,fitted(SES)[,1])
                         ),
              obs_estimadores = c(rep("NO2",n),
                        rep("SES",n)
                        )
)
ggplot(dat2, aes(data, no2)) + 
  #geom_point(position=position_jitter(1,3), pch=21, fill="#FF0000AA") +
  geom_line(aes(y=no2,col= obs_estimadores )) +  theme_bw() + xlab('Data (Diaria)') + 
  ylab('NO2')
  


```


---
class: middle
##Métodos suavização exponencial simples  - Aplicação


```{r, echo = FALSE, warning=FALSE, message=FALSE}


forecast(SES, h=5)

```                       
                         
[Explicação da previsão](https://otexts.com/fpp2/ses.html)


---
class: middle
#Método de suavização exponencial de Holt

- Holt (1957) estendeu a suavização exponencial simples para permitir a previsão de dados com uma tendência. 

- Esse método envolve uma equação de previsão e duas equações de suavização (uma para o nível e outra para a tendência)

- Os valores do nível e da tendência da série, no instante t, serão estimados por:

\begin{align}
\bar{Z}_t =& AZ_t + (1-A)(\bar{Z}_{t-1} +\hat{T}_{t-1}), \phantom{11} 0 < A < 1, \phantom{11} \mbox{e} \phantom{11} t = 2, \ldots, N, \\
\bar{T}_t =& C(\bar{Z}_t - \bar{Z}_{t-1}) + (1-C)\hat{T}_{t-1}, \phantom{11} 0 < C < 1, \phantom{11} \mbox{e} \phantom{11} t = 2, \ldots, N.
\end{align}
em que $A$ e $C$ são constantes de suavização.

- Essas fórmulas como em todos os métodos de suavização, modificam estimativas prévias quando uma nova observação é obtida.



---
class: middle
#Método de suavização exponencial de Holt


##Previsão

$$\hat{Z}_{t + h} = \bar{Z}_t + h \hat{T}_t, \forall h > 0,$$
ou seja, a previsão é feita adicionando-se ao valor básico. $(\bar{Z}_t)$ a tendência multiplicada pelo número de passos à frente que se deseja prever $(h)$.


###Determinação das constantes de suavização

- Escolher valores de (A,C) que minimizem o erro quadrático de previsão ("backforecasting")


---
class: middle
#Método de suavização exponencial de Holt - Aplicação

- Vamos analisar a série $A_{10}$ (M-ICV), índice de custo de vida no município de São Paulo; que originalmente possui observações mensais de janeiro de 1970 a junho de 1980.

- Por questões didáticas, vamos analisar a série no período de janeiro de 1970 (t=1) a junho de 1979 (t=114), ou seja, isolamos as 12 ultimas observações com o objetivo de comparar as previsões com os respectivos valores reais.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

url1 = 'https://www.ime.usp.br/~pam/ICV.xls'
a = GET(url1, write_disk(tf <- tempfile(fileext = ".xls")))
dat =  as_tibble(read.xlsx(tf, sheetIndex = 1))
datM_ICV = ts(dat$ICV[1:114], c(1970,1), frequency=12)

```

---
class: middle
###Método de suavização exponencial de Holt - Aplicação


```{r, echo = FALSE, warning=FALSE, message=FALSE}

autoplot(datM_ICV)

```


---
class: middle
###Método de suavização exponencial de Holt - Aplicação

```{r, echo = FALSE, warning=FALSE, message=FALSE}
Holt = HoltWinters(datM_ICV, beta=0.3, gamma=FALSE, alpha=0.9)

forecast(Holt, h=12)

```

---
class: middle
###Método de suavização exponencial de Holt - Aplicação

```{r, echo = FALSE, warning=FALSE, message=FALSE}

n = 126

datResp = tibble(data = rep(1:n,3),
             dados_obs = c(
               ts(dat$ICV, c(1970,1), frequency=12),
               c(NA,NA,fitted(Holt)[,1], rep(NA,12)),
               c(rep(NA,114),predict(Holt, 12, prediction.interval=TRUE)[,1])),
              estimadores = c(rep("dados obs",n),
                        rep("HW (ajuste)",n),
                        rep("HW (previsão)",n)
                        )
)

ggplot(datResp , aes(data, dados_obs )) + 
  geom_line(aes(y=dados_obs ,col= estimadores )) +  theme_bw() + xlab('Dados (Mensal)') + ylab('IPI') + ggtitle("Suavização de Holt")
 
```


---
class: middle
#Métodos de suavização para séries sazonais

- Para séries temporais que apresentam um padrão de comportamento mais complexo, existem outras formas de suavização

- Nessa aula veremos o método de Holt-Winters.

Winters, P. R. (1960). Forecasting sales by exponentially weighted moving averages. Management Science, 6, 324–342. (https://doi.org/10.1287/mnsc.6.3.324)

---
class: middle
#Método de suavização exponencial de Holt-Winters

####Equações de Suavização - Série Sazonal Multiplicativa 

\begin{align}
\hat{F}_t =& D\left(\frac{Z_t}{\bar{Z}_t}\right) + (1 - D) \hat{F}_{t - s}, \phantom{11} 0 < D < 1, \phantom{111}, t = s + 1, \ldots, N. \\
\bar{Z}_t =& A\left(\frac{Z_t}{\hat{F}_{t-s}}\right) + (1 - A)(\bar{Z}_{t-1} + \hat{T}_{t-1}), \phantom{11} 0 < A < 1, \phantom{111}, t = s + 1, \ldots, N. \\
\hat{T}_t =& C(\bar{Z}_t - \bar{Z}_{t-1}) + (1 - C)\hat{T}_{t-1}, \phantom{111}, 0 < C < 1, \phantom{111} t = s+1, \ldots, N.
\end{align}

####Previsão - Série Sazonal Multiplicativa


$$\hat{Z}_{t+h} = (\bar{Z}_t + h\hat{T}_t)\hat{F}_{t+h-s}, \phantom{111} h = 1,2, \ldots, s$$




---
class: middle
#Método de suavização exponencial de Holt-Winters

####Equações de Suavização - Série Sazonal Aditiva

\begin{align}
\hat{F}_t =& D\left(Z_t - \bar{Z}_t\right) + (1 - D) \hat{F}_{t - s}, \phantom{11} 0 < D < 1, \phantom{11} t = s + 1, \ldots, N. \\
\bar{Z}_t =& A\left(Z_t - \hat{F}_{t-s}\right) + (1 - A)(\bar{Z}_{t-1} + \hat{T}_{t-1}), \phantom{11} 0 < A < 1, \phantom{11} t = s + 1, \ldots, N. \\
\hat{T}_t =& C(\hat{Z}_t - \bar{Z}_{t-1}) + (1 - C)\hat{T}_{t-1}, \phantom{11} 0 < C < 1, \phantom{11} t = s+1, \ldots, N.
\end{align}

####Previsão - Série Sazonal Aditiva

$$\hat{Z}_{t+h} = \bar{Z}_t + h\hat{T}_t + \hat{F}_{t+h-s}, \phantom{111} h = 1,2, \ldots, s.$$

---
class: middle
###Método de Holt Winters Série Multiplicativa - Aplicação 

$$Z_t = \mu_t F_t + T_t + a_t, \phantom{111}, t = 1, \ldots, N.$$

- Aplicamos o método HW multiplicativo a série IPI.

- É uma série periódica com $s=12$, durante o período de janeiro de 1969 a julho de 1979.

---
class: middle
###Método de Holt Winters Série Multiplicativa - Aplicação 

```{r, echo = FALSE, warning=FALSE, message=FALSE}

x = c(7.78,7.351,8.317,8.036, 8.424,8.3,8.985, 8.589, 8.564,8.614, 8.102,8.044,
      8.209, 7.738, 8.828, 9.150,8.960, 9.282, 9.934, 9.546, 9.572, 10.272, 9.991, 9.537,
      8.761, 8.501, 9.642, 9.058, 9.256, 9.799, 10.828, 11.063, 10.652, 11.278, 10.661, 10.500,
      9.759, 9.876, 10.664,10.110, 11.055,11.615, 11.730, 12.587,12.046, 12.852, 12.259, 12.214,
      11.798, 11.278, 11.945, 11.695, 12.734, 13.405, 13.836, 14.388, 14.069, 15.519, 14.680, 14.104,
      13.577, 12.451, 13.856, 13.812, 14.280, 13.692, 15.502, 15.423, 14.947, 16.031,14.462, 13.791,
      14.829, 15.297, 16.330, 15.807, 16.623, 17.196, 17.691, 18.012, 17.625, 18.244, 17.102, 16.744,
      15.385, 15.062, 17.896, 16.262, 17.820, 17.911, 17.818, 18.410, 17.658, 18.273, 17.922, 16.987,
      16.681, 15.886, 18.281, 17.478, 18.412, 18.849, 19.023, 20.372, 19.262, 20.570, 19.304, 18.407,
      18.633, 17.497, 19.470, 18.884, 20.308, 20.146, 20.258, 21.614, 19.717, 22.133, 20.503, 18.800,
      19.577, 18.992, 21.022, 19.064,21.067, 21.553, 22.513)

datM_IPI = ts(x, c(1969,1), c(1979,7),frequency=12)

```


```{r, echo = FALSE, warning=FALSE, message=FALSE}

autoplot(datM_IPI)

```


---
class: middle
###Método de Holt Winters Série Multiplicativa - Aplicação

```{r, echo = FALSE, warning=FALSE, message=FALSE}

HoltW = HoltWinters(datM_IPI, beta=0.1, gamma=0.3, alpha=0.3,
                   seasonal=c("multiplicative"))

forecast(HoltW, h=12)

```

---
class: middle
###Método de Holt Winters Série Multiplicativa - Aplicação

```{r, echo = FALSE, warning=FALSE, message=FALSE}


n = 127

datResp = tibble(data = rep(1:n,3),
             dados_obs = c(
               ts(x, c(1969,1),frequency=12), 
               c(fitted(HoltW)[,1], rep(NA,12)),
               c(rep(NA,115),predict(HoltW, 12, prediction.interval=TRUE)[,1])),
              estimadores = c(rep("dados obs",n),
                        rep("HW (ajuste)",n),
                        rep("HW (previsão)",n)
                        )
)

ggplot(datResp , aes(data, dados_obs )) + 
  geom_line(aes(y=dados_obs ,col= estimadores )) +  theme_bw() + xlab('Dados (Mensal)') + ylab('IPI') + ggtitle("Série Multiplicativa")
 


```
